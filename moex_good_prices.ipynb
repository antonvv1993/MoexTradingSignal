{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "95ae8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import aiomoex\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class MoexDataRetrival():\n",
    "    \n",
    "    def __init__(self, start_date : str, end_date : str):\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "    #get a stock list from MOEX exchange\n",
    "    async def get_stock_list(self) -> pd.DataFrame:\n",
    "        request_url = \"https://iss.moex.com/iss/engines/stock/\" \"markets/shares/boards/TQBR/securities.json\"\n",
    "        arguments = {\n",
    "            \"securities.columns\": (\n",
    "                \"SECID,\"\n",
    "                \"REGNUMBER,\"\n",
    "                \"LOTSIZE,\"\n",
    "                \"SHORTNAME,\"\n",
    "                \"BOARDID,\"\n",
    "                \"LISTLEVEL,\"\n",
    "                \"ISIN,\"\n",
    "                \"ISSUECAPITALIZATION,\"\n",
    "                \"FACEVALUE,\"\n",
    "                \"ISSUESIZE,\"\n",
    "            )\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            iss = aiomoex.ISSClient(session, request_url, arguments)\n",
    "            data = await iss.get()\n",
    "            data = pd.DataFrame(data[\"securities\"])\n",
    "            return data['SECID']\n",
    "\n",
    "    #get a stock list from MOEX exchange\n",
    "    async def get_stock_list_with_extra_data(self) -> pd.DataFrame:\n",
    "        request_url = \"https://iss.moex.com/iss/engines/stock/\" \"markets/shares/boards/TQBR/securities.json\"\n",
    "        arguments = {\n",
    "            \"securities.columns\": (\n",
    "                \"SECID,\"\n",
    "                \"REGNUMBER,\"\n",
    "                \"LOTSIZE,\"\n",
    "                \"SHORTNAME,\"\n",
    "                \"BOARDID,\"\n",
    "                \"LISTLEVEL,\"\n",
    "                \"ISIN,\"\n",
    "                \"ISSUECAPITALIZATION,\"\n",
    "                \"FACEVALUE,\"\n",
    "                \"ISSUESIZE,\"\n",
    "            )\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            iss = aiomoex.ISSClient(session, request_url, arguments)\n",
    "            data = await iss.get()\n",
    "            data = pd.DataFrame(data[\"securities\"])\n",
    "            return data\n",
    "\n",
    "    #get a price history for the ticker in TQBR regime  \n",
    "    \n",
    "    async def get_price_history(self, ticker : str) -> pd.DataFrame:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            columns=[\n",
    "                    \"BOARDID\", \"TRADEDATE\", \"SHORTNAME\", \"SECID\", \"NUMTRADES\",\n",
    "                    \"VALUE\", \"OPEN\", \"LOW\", \"HIGH\", \"LEGALCLOSEPRICE\",\n",
    "                    \"WAPRICE\", \"CLOSE\", \"VOLUME\", \"MARKETPRICE2\", \"MARKETPRICE3\",\n",
    "                    \"ADMITTEDQUOTE\", \"MP2VALTRD\", \"MARKETPRICE3TRADESVALUE\",\n",
    "                    \"ADMITTEDVALUE\", \"WAVAL\"\n",
    "                ]\n",
    "            data = await aiomoex.get_board_history(session, ticker,columns = columns,start = self.start_date, end = self.end_date)\n",
    "            df = pd.DataFrame(data)\n",
    "            return df\n",
    "\n",
    "    #get a price history for the ticker in TQBR regime  \n",
    "    async def get_multiple_price_histories(self, tickers : pd.Series) -> pd.DataFrame:\n",
    "        tasks = [get_price_history(ticker,self.start_date,self.end_date) for ticker in tickers]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        combined_df = pd.concat(results, ignore_index=True)\n",
    "        combined_df['TRADEDATE'] = pd.to_datetime(combined_df['TRADEDATE'])\n",
    "        condition = (combined_df['SECID'] == 'GMKN') & (combined_df['TRADEDATE'] <= '2024-04-01')\n",
    "        combined_df.loc[condition, 'CLOSE'] = combined_df.loc[condition, 'CLOSE'] / 100\n",
    "        condition = (combined_df['SECID'] == 'TRNFP') & (combined_df['TRADEDATE'] <= '2024-02-14')\n",
    "        combined_df.loc[condition, 'CLOSE'] = combined_df.loc[condition, 'CLOSE'] / 100\n",
    "        return combined_df\n",
    "\n",
    "\n",
    "    #check the stocks which are trading near min for the last n years\n",
    "    def get_tickers_which_we_can_buy_now(self, df : pd.DataFrame, years : int, percent : float):\n",
    "\n",
    "        # Ensure TRADEDATE is in datetime format\n",
    "        df['TRADEDATE'] = pd.to_datetime(df['TRADEDATE'])\n",
    "        # Calculate date n years ago\n",
    "        today = datetime.now()\n",
    "        n_years_ago = today - timedelta(days=years*365)\n",
    "\n",
    "        # Filter data for the last n years\n",
    "        df_last_n_years = df[df['TRADEDATE'] >= n_years_ago]\n",
    "\n",
    "        # Calculate the minimum and maximum closing price for each ticker over the last 2 years\n",
    "        min_prices = df_last_n_years.groupby('SECID')['CLOSE'].min().reset_index()\n",
    "        min_prices.rename(columns={'CLOSE': 'MIN_CLOSE'}, inplace=True)\n",
    "        max_prices = df_last_n_years.groupby('SECID')['CLOSE'].max().reset_index()\n",
    "        max_prices.rename(columns={'CLOSE': 'MAX_CLOSE'}, inplace=True)\n",
    "\n",
    "        # Get the latest closing price for each ticker\n",
    "        latest_prices = df_last_n_years.sort_values('TRADEDATE').groupby('SECID').tail(1).reset_index()\n",
    "        latest_prices = latest_prices[['SECID', 'CLOSE']].rename(columns={'CLOSE': 'LATEST_CLOSE'})\n",
    "\n",
    "        # Merge the minimum, maximum, and latest prices\n",
    "        merged_df = pd.merge(min_prices, max_prices, on='SECID')\n",
    "        merged_df = pd.merge(merged_df, latest_prices, on='SECID')\n",
    "\n",
    "        # Filter tickers where the latest closing price is not higher than x% above the minimum price\n",
    "        condition = merged_df['LATEST_CLOSE'] <= merged_df['MIN_CLOSE'] * (1+percent/100)\n",
    "        result = merged_df[condition]\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "class BiddingResultsDBLoader():\n",
    "    \n",
    "    #main table name - это название основной таблицы где лежат итоги торгов\n",
    "    def __init__(self, path_to_db : str, main_table_name : str):\n",
    "        \n",
    "        self.path_to_db = path_to_db\n",
    "        self.main_table_name = main_table_name\n",
    "        \n",
    "    #remove duplicates from table\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"\n",
    "        Connects to an SQLite database and removes duplicate rows from the specified table.\n",
    "\n",
    "        Parameters:\n",
    "        database_path (str): The path to the SQLite database file.\n",
    "        table_name (str): The name of the table from which to remove duplicates.\n",
    "        \"\"\"\n",
    "        # Connect to the SQLite database\n",
    "        conn = sqlite3.connect(self.database_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Define the query to remove duplicates\n",
    "        delete_duplicates_query = f\"\"\"\n",
    "        WITH duplicates AS (\n",
    "            SELECT \n",
    "                ROWID,\n",
    "                BOARDID,\n",
    "                TRADEDATE,\n",
    "                CLOSE,\n",
    "                VOLUME,\n",
    "                VALUE,\n",
    "                SECID,\n",
    "                ROW_NUMBER() OVER (PARTITION BY BOARDID, TRADEDATE, SECID ORDER BY ROWID) AS rn\n",
    "            FROM \n",
    "                {self.main_table_name}\n",
    "        )\n",
    "        DELETE FROM {self.main_table_name}\n",
    "        WHERE ROWID IN (\n",
    "            SELECT ROWID\n",
    "            FROM duplicates\n",
    "            WHERE rn > 1\n",
    "        );\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Execute the query to delete duplicates\n",
    "            cursor.execute(delete_duplicates_query)\n",
    "            # Commit the transaction\n",
    "            conn.commit()\n",
    "        except sqlite3.Error as error:\n",
    "            print(f\"Error while removing duplicates: {error}\")\n",
    "        finally:\n",
    "            # Close the connection\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "\n",
    "    def insert_data_to_database(self, df : pd.DataFrame):\n",
    "        conn = sqlite3.connect(self.path_to_db)\n",
    "        df.to_sql(self.main_table_name, conn, if_exists='append', index=False)\n",
    "        remove_duplicates(self.path_to_db,self.main_table_name)\n",
    "        conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "999f9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "moex_data_loader = MoexDataRetrival('2024-05-27','2024-05-27')\n",
    "stock_list = asyncio.run(moex_data_loader.get_stock_list())\n",
    "trade_data = asyncio.run(moex_data_loader.get_multiple_price_histories(stock_list))\n",
    "\n",
    "db_loader = BiddingResultsDBLoader('/Users/antonvolkov/Desktop/MoexTrading/MoexData.db','MOEXDATA')\n",
    "db_loader.insert_data_to_database(trade_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e061d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
