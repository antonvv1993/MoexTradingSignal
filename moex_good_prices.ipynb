{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ca4c1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import aiomoex\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#get a stock list from MOEX exchange\n",
    "async def get_stock_list():\n",
    "    request_url = \"https://iss.moex.com/iss/engines/stock/\" \"markets/shares/boards/TQBR/securities.json\"\n",
    "    arguments = {\"securities.columns\": (\"SECID,\" \"REGNUMBER,\" \"LOTSIZE,\" \"SHORTNAME\")}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        iss = aiomoex.ISSClient(session, request_url, arguments)\n",
    "        data = await iss.get()\n",
    "        data = pd.DataFrame(data[\"securities\"])\n",
    "        return data['SECID']\n",
    "\n",
    "#get a stock list from MOEX exchange\n",
    "async def get_stock_list_with_extra_data():\n",
    "    request_url = \"https://iss.moex.com/iss/engines/stock/\" \"markets/shares/boards/TQBR/securities.json\"\n",
    "    arguments = {\"securities.columns\": (\"SECID,\" \"REGNUMBER,\" \"LOTSIZE,\" \"SHORTNAME\")}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        iss = aiomoex.ISSClient(session, request_url, arguments)\n",
    "        data = await iss.get()\n",
    "        data = pd.DataFrame(data[\"securities\"])\n",
    "        return data\n",
    "\n",
    "#get a price history for the ticker in TQBR regime    \n",
    "async def get_price_history(ticker):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        data = await aiomoex.get_board_history(session, ticker)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['TICKER'] = ticker\n",
    "        return df\n",
    "\n",
    "#get a price history for the ticker in TQBR regime  \n",
    "async def get_multiple_price_histories(tickers):\n",
    "    tasks = [get_price_history(ticker) for ticker in tickers]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    combined_df = pd.concat(results, ignore_index=True)\n",
    "    combined_df['TRADEDATE'] = pd.to_datetime(combined_df['TRADEDATE'])\n",
    "    condition = (combined_df['TICKER'] == 'GMKN') & (combined_df['TRADEDATE'] <= '2024-04-01')\n",
    "    combined_df.loc[condition, 'CLOSE'] = combined_df.loc[condition, 'CLOSE'] / 100\n",
    "    condition = (combined_df['TICKER'] == 'TRNFP') & (combined_df['TRADEDATE'] <= '2024-02-14')\n",
    "    combined_df.loc[condition, 'CLOSE'] = combined_df.loc[condition, 'CLOSE'] / 100\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "#check the stocks which are trading near min for the last n years\n",
    "def get_tickers_which_we_can_buy_now(df, years, percent):\n",
    "\n",
    "    # Ensure TRADEDATE is in datetime format\n",
    "    df['TRADEDATE'] = pd.to_datetime(df['TRADEDATE'])\n",
    "    # Calculate date n years ago\n",
    "    today = datetime.now()\n",
    "    n_years_ago = today - timedelta(days=years*365)\n",
    "    \n",
    "    # Filter data for the last n years\n",
    "    df_last_n_years = df[df['TRADEDATE'] >= n_years_ago]\n",
    "    \n",
    "    # Calculate the minimum and maximum closing price for each ticker over the last 2 years\n",
    "    min_prices = df_last_n_years.groupby('TICKER')['CLOSE'].min().reset_index()\n",
    "    min_prices.rename(columns={'CLOSE': 'MIN_CLOSE'}, inplace=True)\n",
    "    max_prices = df_last_n_years.groupby('TICKER')['CLOSE'].max().reset_index()\n",
    "    max_prices.rename(columns={'CLOSE': 'MAX_CLOSE'}, inplace=True)\n",
    "    \n",
    "    # Get the latest closing price for each ticker\n",
    "    latest_prices = df_last_n_years.sort_values('TRADEDATE').groupby('TICKER').tail(1).reset_index()\n",
    "    latest_prices = latest_prices[['TICKER', 'CLOSE']].rename(columns={'CLOSE': 'LATEST_CLOSE'})\n",
    "    \n",
    "    # Merge the minimum, maximum, and latest prices\n",
    "    merged_df = pd.merge(min_prices, max_prices, on='TICKER')\n",
    "    merged_df = pd.merge(merged_df, latest_prices, on='TICKER')\n",
    "    \n",
    "    # Filter tickers where the latest closing price is not higher than x% above the minimum price\n",
    "    condition = merged_df['LATEST_CLOSE'] <= merged_df['MIN_CLOSE'] * (1+percent/100)\n",
    "    result = merged_df[condition]\n",
    "    \n",
    "    return result\n",
    "\n",
    "#remove duplicates from table\n",
    "def remove_duplicates(database_path, table_name):\n",
    "    \"\"\"\n",
    "    Connects to an SQLite database and removes duplicate rows from the specified table.\n",
    "\n",
    "    Parameters:\n",
    "    database_path (str): The path to the SQLite database file.\n",
    "    table_name (str): The name of the table from which to remove duplicates.\n",
    "    \"\"\"\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Define the query to remove duplicates\n",
    "    delete_duplicates_query = f\"\"\"\n",
    "    WITH duplicates AS (\n",
    "        SELECT \n",
    "            ROWID,\n",
    "            BOARDID,\n",
    "            TRADEDATE,\n",
    "            CLOSE,\n",
    "            VOLUME,\n",
    "            VALUE,\n",
    "            TICKER,\n",
    "            ROW_NUMBER() OVER (PARTITION BY BOARDID, TRADEDATE, TICKER ORDER BY ROWID) AS rn\n",
    "        FROM \n",
    "            {table_name}\n",
    "    )\n",
    "    DELETE FROM {table_name}\n",
    "    WHERE ROWID IN (\n",
    "        SELECT ROWID\n",
    "        FROM duplicates\n",
    "        WHERE rn > 1\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Execute the query to delete duplicates\n",
    "        cursor.execute(delete_duplicates_query)\n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "    except sqlite3.Error as error:\n",
    "        print(f\"Error while removing duplicates: {error}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "\n",
    "def insert_data_to_database(database_name, table_name, df):\n",
    "    conn = sqlite3.connect(database_name)\n",
    "    df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "    remove_duplicates(database_name,table_name)\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c93b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = asyncio.run(get_stock_list())\n",
    "stock_list_extra_data = asyncio.run(get_stock_list_with_extra_data())\n",
    "price_history = asyncio.run(get_price_history('GAZP'))\n",
    "combined_df = asyncio.run(get_multiple_price_histories(stock_list))\n",
    "pivot_df = combined_df.pivot(index='TRADEDATE', columns='TICKER', values='CLOSE')\n",
    "filered_df = get_tickers_which_we_can_buy_now(combined_df,3,10)\n",
    "insert_data_to_database('/Users/antonvolkov/Desktop/MoexTrading/MoexData.db','moexdata',combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2821ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
